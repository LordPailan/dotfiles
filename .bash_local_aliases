#!/bin/bash
# vi: ft=sh ts=2 sw=2

# functions and aliases, loaded on session start.
# By using meaningful one-line comments to functions, they'll get nicely printed
# by means of the 'my_commands' help function (defined in ~/.bashrc)

# enable ansible 2.x
alias ansible.enable.27='_ansible_enable "2.7"'
alias ansible.enable.24='_ansible_enable "2.4"'
_ansible_enable() {
  version=$1
  venv_dir="${VENVS_HOME}/ansible_${version}"
  [ -d "${venv_dir}" ] && source "${venv_dir}/bin/activate" && return

  venv_global_binary="virtualenv --python=python3.7"
  tmp_reqs=$(mktemp)
  echo "ansible==${version}" >> "${tmp_reqs}"
  _virtualenver.core "${venv_dir}" "${venv_global_binary}" "-r ${tmp_reqs}"
}

# disable Ansible
alias ansible.disable='deactivate'

# re-source all aliases
alias.source() {
  source "${HOME}/.bashrc"
  #source "${HOME}/.bash_local_aliases"
}

# Edit aliases fast
alias.edit() {
  vim "${HOME}/.bash_local_aliases" "${HOME}/.bash_private_vars"
}

# kills anything similar to argument passed
sys.kill() {
  regex=$1
  while [ ! -z "${regex}" ] ; do
    ps aux | grep -i ${regex} | awk '{print $2}' | xargs kill -9 > /dev/null 2>&1
    shift
    regex=$1
  done
}

# Returns true if the current dir is a git repository
is.repo() {
  [ ! -z "$(git rev-parse \
    --git-dir --is-inside-git-dir \
    --is-bare-repository --is-inside-work-tree \
    --short HEAD 2>/dev/null)" ]
}

# Convert a file from RST to Markdown
rst2md() {
  [ -z "$(which pandoc)" ] && error "pandoc is not installed"

  local input="$1"
  [ -z "${input}" -o "${input}" = "${input//.rst/}" ] && \
    error "Need a rst file as input"

  local output="${input//.rst/.md}"
  pandoc "${input}" -f rst -t markdown -o "${output}"
}

# Report of disk space usage in current path
sys.disk_usage() {
  for dir in $(\ls  -h .) ; do
    total=$(du -ch "$dir" | grep total | grep -E -o "[0-9]+[GM]")
    [ ! -z "${total}" ] && echo "Disk usage in $dir: $total"
  done
}

# Find something similar to argument, from here downwards
sys.find() {
  local arg=$1
  shift
  [ ! -z "$*" ] && \
    echo "[WARNING] Ignoring extra input parameters: $*"
  find . -iname "*${arg}*"
}

# Rename a bunch of files
sys.renamer() {
  local where file_name file_dir
  where=${1:-.}
  for file in $(find "${where}" -type f -depth 1) ; do
    file_name="$(basename "$file")"
    file_dir="$(dirname "$file")"
    echo "Type in new name for ${file_name}? [Empty to ignore, \$ matches all]" && read new_name
    [ -z "${new_name}" ] && continue
    new_name="${new_name//\$/$file_name}"
    mv "${file_dir}/${file_name}" "${file_dir}/${new_name}"
  done
}

# Show a pretty error message
error() { echo "[ERROR] $*" ; }

# 'Darwin' for Mac, 'Linux' or similar elsewhere
is.mac() {
  [ "$(uname -s)" == "Darwin" ]
}

_get_bash_completion() {
  is.mac && echo "/usr/local/etc/bash_completion" || echo "/etc/bash_completion"
}

PYTHON_36_SUFFIX="_p3.6"
PYTHON_37_SUFFIX="_p3.7"
PYTHON_2_SUFFIX=""
VENVS_HOME="$(cd "${HOME}/.venvs" && pwd)"

_virtualenver.core() {
  local venv_name venv_dir venv_binaries venv_pip venv_activate venv_global_binary
  venv_name="$1" && shift
  venv_global_binary="$1" && shift
  venv_dir="${VENVS_HOME}/$( basename "${venv_name}" )"
  venv_binaries="${venv_dir}/bin"
  venv_pip="${venv_binaries}/pip"
  venv_activate="${venv_binaries}/activate"

  # Virtualenv at a global level is a must
  [ -z "$(which virtualenv)" ] && pip install -q virtualenv

  # If venv'd PIP doesn't exist, install the virtualenv
  [ ! -f "${venv_pip}" ] && ${venv_global_binary} "${venv_dir}"

  # Use pip syntax to install requirements
  "${venv_pip}" install ${*:-.}

  # I use this with Syntastic :-)
  "${venv_pip}" install pylint

  # Auto activate
  source "${venv_activate}"
}

_virtualenver37() {
  local venv_name venv_global_binary
  venv_name="$(_venv.name)$PYTHON_37_SUFFIX"
  venv_global_binary="virtualenv --python=python3.7"

  _virtualenver.core "${venv_name}" "${venv_global_binary}" "$@"
}

_virtualenver36() {
  local venv_name venv_global_binary
  venv_name="$(_venv.name)$PYTHON_36_SUFFIX"
  venv_global_binary="virtualenv --python=python3.6"

  _virtualenver.core "${venv_name}" "${venv_global_binary}" "$@"
}

_virtualenver() {
  local venv_name venv_global_binary
  venv_name="$(_venv.name)$PYTHON_2_SUFFIX"
  venv_global_binary="virtualenv --python=python2"

  _virtualenver.core "${venv_name}" "${venv_global_binary}" "$@"
}

_venv.name() {
  root_dir=$( git rev-parse --show-toplevel 2> /dev/null || true )
  [ -z "${root_dir}" ] && root_dir="${PWD}"
  basename "${root_dir}"
}

_activate.core() {
  local venv_suffix venv_name venv_dir venv_activate
  venv_suffix=$1
  venv_name="$(_venv.name)$venv_suffix"
  venv_dir="${VENVS_HOME}/${venv_name}"
  venv_activate="${venv_dir}/bin/activate"

  [ ! -f "${venv_activate}" ] && echo "No virtualenv called '$venv_name'" && return 1
  source "${venv_activate}"
}

_activate36() {
  _activate.core "$PYTHON_36_SUFFIX"
}

_activate37() {
  _activate.core "$PYTHON_37_SUFFIX"
}

_activate() {
  _activate.core "$PYTHON_2_SUFFIX"
}

# Wrapper for autocompletion script found in "$(_get_bash_completion).d/repo"
_repo() {
  base_dir="${_REPO_AUTOCOMPLETE_BASE_DIR}"

  # This should only get executed the first time
  if [ ! -d "${base_dir}" ] ; then
    read -r -e -p "Base repo dir is not set, or is not a directory. Enter path to repositories base dir: " input
    base_dir="${input/#\~/$HOME}"
    [ ! -d "${base_dir}" ] && \
      echo "Invalid directory: ${base_dir}" && return

    export _REPO_AUTOCOMPLETE_BASE_DIR=${base_dir}
    echo "Remember to add this to your profile file:"
    echo
    echo "# Used by '$( _get_bash_completion )/repo'"
    echo "export _REPO_AUTOCOMPLETE_BASE_DIR=${_REPO_AUTOCOMPLETE_BASE_DIR}"
    echo
    return
  fi

  # This depends on the output of the 'repo' autocomplete
  local repo_name=${2:-$1}
  local fulldir="${base_dir}/${repo_name}"
  if [ ! -d "${fulldir}" ] ; then
    echo "'${fulldir}' is not a directory"
  else
    cd "${fulldir}" || return
  fi
}

_despawn() {
  local service=$1
  local service_name="spawned_${service//\//_}"
  local ids=$(docker ps -a | grep "${service_name}" | awk '{print $1}')
  [ ! -z "$ids" ] && \
    printf "Killing old '%s': %s\n" "$1" "$(docker rm -f "${ids}")"
}

_spawn() {
  # Service name MUST match image name
  local service=$1
  local service_name="spawned_${service//\//_}"
  shift

  # ports and stuff
  #args=$*

  # first kill old one, if any
  _despawn "${service}" || true

  # And spawn a new service
  printf "Spawning new '%s': %s'\n" "${service}" "$(docker run -d --rm  --name "${service_name}" "$@" "$service")"
}


# Free some Docker disk space
docker.free_space() {
  exited_ps_before=$(docker ps -a -q  -f 'status=exited')
  exited_ps_before_count=$(echo "${exited_ps_before}" | grep -v ^$ | wc -l | tr -d ' ')
  [ ${exited_ps_before_count} -gt 0 ] && \
    echo "Deleting ${exited_ps_before_count}  containers with status 'Exited'..." && \
    docker rm -f $(echo ${exited_ps_before} | xargs)

  dangling_images_before=$(docker images -q -a -f "dangling=true")
  dangling_images_before_count=$(echo "${dangling_images_before}" | grep -v ^$ | wc -l | tr -d ' ')
  [ ${dangling_images_before_count} -gt 0 ] && \
    echo "Deleting ${dangling_images_before_count} dangling images..." && \
    docker rmi -f $(echo ${dangling_images_before} | xargs)

  # Delete volumes
  docker volume rm $(docker volume ls -q)
}

# export AWS credentials for given profile
aws.load_credentials() {
  _unset() { unset AWS_PROFILE AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY ; }
  _hint() { echo && echo "[HINT] Use '-1' to unload current session" ; }

  # 'default' is not a profile we want to use
  local profiles more_profiles aws_access_key_id aws_secret_access_key chosen_profile
  profiles=$(grep -o '\[.*\]' ~/.aws/credentials | tr -d "][" )
  more_profiles=$(grep -o '\[.*\]' ~/.aws/config | tr -d "][" | cut -d' ' -f2)
  profiles="$(echo $profiles $more_profiles | tr ' ' '\n' | grep -v 'default' | sort -u | xargs)"
  chosen_profile=$1
  if [ -z "${chosen_profile}" ] ; then
    echo "You need to choose one AWS profile from this list:"  && echo "${profiles}"
    _hint
    return 1
  elif [ "${chosen_profile}" = "-1" ] ; then
    _unset
    echo "AWS information unloaded from session"
    return 0
  elif [ "${profiles}" = "${profiles//${chosen_profile}}" ] ; then
    echo "Profile '${chosen_profile}' not found. Valid profiles are:" && echo "${profiles}"
    _hint
    return 2
  fi

  _unset
  mfa_token=$2
  if [ -z "${mfa_token}" ] ; then
    echo "MFA token is missing, loading previous session..."
    _hint

    aws_access_key_id=$(aws configure get aws_access_key_id --profile ${chosen_profile})
    [ -z "${aws_access_key_id}" ] && \
      echo && error "No credentials found, you need to authenticate again" && \
      return 3

    export AWS_PROFILE=${chosen_profile}
    export AWS_ACCESS_KEY_ID=$(aws configure get aws_access_key_id)
    export AWS_SECRET_ACCESS_KEY=$(aws configure get aws_secret_access_key)
    export AWS_SESSION_TOKEN=$(aws configure get aws_session_token)
    export AWS_REGION=$(aws configure get region)
  else
    echo "Creating new temporary session with MFA token..."
    cross_account_role=$(aws configure get x_role_arn --profile $chosen_profile)
    [ -z "${cross_account_role}" ] && \
      error "you need to configure chosen role ARN as 'x_role_arn' in ~/.aws/config, under [profile ${chosen_profile}" && \
      return 4

    mfa_iam=$(aws configure get x_mfa_serial --profile $chosen_profile)
    [ -z "${cross_account_role}" ] && \
      error "you need to configure your MFA ARN as 'x_mfa_arn' in ~/.aws/config, under [profile ${chosen_profile}" && \
      return 5

    temp_keys=($(aws sts assume-role --role-arn $cross_account_role --role-session-name session-$1 --serial-number $mfa_iam --token-code $mfa_token --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' --output text))
    [ $? -ne 0 ] && return 6

    export AWS_PROFILE=${chosen_profile}
    export AWS_ACCESS_KEY_ID=${temp_keys[0]}
    export AWS_SECRET_ACCESS_KEY=${temp_keys[1]}
    export AWS_SESSION_TOKEN=${temp_keys[2]}
    export AWS_REGION=$(aws configure get region)

    aws configure set aws_secret_access_key ${AWS_SECRET_ACCESS_KEY}
    aws configure set aws_access_key_id ${AWS_ACCESS_KEY_ID}
    aws configure set aws_session_token ${AWS_SESSION_TOKEN}
  fi
}

# Remove given line from file
sys.delete_line() {
  [ $# -ne 2 ] && echo "Usage: ${0} <line_to_delete> <file_name>" && return 1
  line_no=$1
  file=$2
  [ ! -f "${file}" ] && echo "File does not exist" && return 1
  [ ${line_no} -gt $(wc -l $2| awk '{print $1}') ] && echo "Line ${line_no} not found in file ${file}" && return 1

  sed -i -e "${line_no}d" ${file}
}

# Remove given ~/.ssh/known_hosts line
ssh.delete_line() {
  [ $# -ne 1 ] && echo "Usage: ${0} <line_to_delete>" && return 1
  sys.delete_line "${1}" ~/.ssh/known_hosts
}


# Remove duplicated lines from input file into stdout
sys.duprm() {
  if [ "$#" -ne 1 ] ; then
    echo "Missing input file"
    return 1
  fi
  awk '!x[$0]++' "$1"
}

# Allows overriding of VIM commands
vim() {
  first_param=$1
  case "${first_param}" in
    checkout|commit|pull|push)
      command echo "Lo que tu quieres es el 'git', negro.... en fin... que el día que me muera...." && read
      command git "$@"
      ;;
    git*)
      shift;
      command echo "Casi seguro que se te fué la olla again, vamos a pasar del vim ese.... me muero y no te educo..."
      command git "$@" ;;
    modified|mod*)
      modified_files=$(git status -s | grep -v '^\s*M^' | sed -E 's/^.*M //g' | xargs)
      command vim ${modified_files} ;;
    vim*)
      shift ; vim "$@" ;;
    *)
      command vim "$@" ;;
  esac
}

# URL Escape a string
web.escape() {
  [ -z $(which perl) ] && error "PERL is not installed in your system" && return 1
  perl -MURI::Escape -e 'print uri_escape($ARGV[0]);' "${1}"
}

# Allows overriding GIT commands
git() {

  _get_repo_n_project() {
    remote="$1" ; [ -z "${remote}" ] && \
      remote=$(git remote get-url --push origin)
    if echo "${remote}" | grep -q "${GITLAB_REPO}" ; then
      _get_gitlab_repo_and_project "$@"
    else
      _get_bb_repo_n_project "$@"
    fi
  }

  # Returns a two-item array!!
  _get_bb_repo_n_project() {
    repo_ssh="$1" ; [ -z "${repo_ssh}" ] && \
      repo_ssh=$(git remote show origin -n | grep 'Fetch URL' | cut -d':' -f2- | tr -d ' ')
    echo "${repo_ssh}" | sed -Ee 's#.*\.com(:[0-9]*/|:|/)##g' -e 's#\.git$##g' | tr '/' ' '
  }

  # Returns a two-item array!!
  _get_gitlab_repo_and_project() {
    repo_ssh="$1" ; [ -z "${repo_ssh}" ] && \
      repo_ssh="$(git remote get-url --push origin)"
    echo "${repo_ssh}" | grep -Eio '[0-9a-z]+\/[0-9a-z_-]+\.git$' | sed -e 's/.git$//' | tr '/' ' '
  }

  _get_repo_url() {
    repo_and_project=($( _get_repo_n_project "$1" ))
    remote="$1" ; [ -z "${remote}" ] && \
      remote=$(git remote get-url --push origin)
    if echo "${remote}" | grep -q "${GITLAB_REPO}" ; then
      printf "https://${GITLAB_REPO}/%s/%s" "${repo_and_project[0]}" "${repo_and_project[1]}"
    else
      printf "${BITBUCKET_REPO}/projects/%s/repos/%s" "${repo_and_project[0]}" "${repo_and_project[1]}"
    fi
  }

  _get_branch_name() {
    git rev-parse --abbrev-ref HEAD
  }

  case "$1" in
    help*)
      echo && command git --help && echo
      echo "Custom git commands:" && echo
      echo "  branchD   Delete all local, non-merged branches + unused remotes"
      echo "  perrete   Pushes current branchs and opens browser in the Pull Request page"
      echo "  pushete   Pushes current branch"
      echo "  open      Opens current repo's page in browser"
      echo "  klone     Clones given repo in ssh-format to ~/Stuff/<project>/<repo>"
      ;;
    blame*)
      echo "Probablemente tu, así que mejor no preguntes" ;;
    branchD*)
      git branch --no-color --merged | command grep -vE "^(\*|\s(master|develop|dev)\s$)" | command xargs -n 1 git branch -d
      git fetch -puta
      ;;
    perrete*)
      branch_name=$( _get_branch_name )
      command git push -u origin "${branch_name}"

      repo_and_project=($( _get_bb_repo_n_project ))
      project_url=$(printf "${BITBUCKET_REPO}/projects/%s/repos/%s/pull-requests" "${repo_and_project[0]}" "${repo_and_project[1]}")

      url_params=$(printf "create&targetBranch=refs/heads/develop&sourceBranch=refs/heads/%s" "${branch_name}")
      escaped_params=${url_params//\//%2F}

      final_url="${project_url}?${escaped_params}"
      sys.open "${final_url}"
      ;;
    pushete*)
      # pushes current branch and opens browser in repo webpage
      branch_name=$( _get_branch_name )
      [ ! -z "${branch_name}" ] && \
        command git push -u origin "${branch_name}" && git open
      ;;
    checkete*)
      # like checkout -b but parsing incoming text into a proper branch name
      shift; [ "${1}" == "-b" ] && shift;
      branch_name=$(echo "${@}" | sed -Ee 's/[[:space:]:]+/_/g' )
      command git checkout -b "${branch_name}"
      ;;
    git*)
      shift ; git "$@" ;;
    open*)
      shift ; project_url=$( _get_repo_url "$1" )
      sys.open ${project_url}
      ;;
    klone*)
      shift; repo=$1 ; [ -z "${repo}" ] && return $(command git clone "$@")
      parts=($( _get_repo_n_project "${repo}" ))
      target_dir="$HOME/Stuff/${parts[0]}/${parts[1]}"
      [ ! -d "${target_dir}" ] && command git clone "${repo}" "${target_dir}"
      cd "${target_dir}" || return
      ;;
    *)
      command git "$@" ;;
  esac
}

# Open AWS console for given tool, using currently logged-in profile
aws.open() {
  region="$(aws configure get region)"
  [ -z "${region}" ] && region="eu-west-1"
  sys.open "https://${region}.console.aws.amazon.com/${1}"
}

# Opens something - an URL, a file.... (OS-independent)
sys.open() {
  open_command=xdg-open ; is.mac && open_command=open
  "${open_command}" "$@"
}

# Thanks: http://stackoverflow.com/questions/10683349/forcing-bash-to-expand-variables-in-a-string-loaded-from-a-file
# Runs all the shell commands written in the given file
shell.expansion() {
  file="$1"
  [ ! -f "$file" ] && echo "Not a file: $file." && exit 1

  data=$(< "$file")
  delimiter="__apply_shell_expansion_delimiter__"
  command="cat <<$delimiter"$'\n'"$data"$'\n'"$delimiter"
  eval "$command"
}

# Open Whatsapp web
web.whatsapp() {
  sys.open "https://web.whatsapp.com"
}

# Open Telegram web
web.telegram() {
  sys.open "https://web.telegram.org"
}

# Search for something from the commmand line
web.search() {
  engine="Duck Duck GO"
  base_url="https://duckduckgo.com/?q="
  search_string="$*"
  [ -z "${search_string}" ] && \
    error "I need something to search...." && return 1

  escaped_search_string=$( web.escape "${search_string}" )
  echo "Let's search for '${search_string}' using '${engine}'...."
  sys.open "${base_url}${escaped_search_string}"
}

# Get the N% of the files of the input file
rand.lines() {
  in=$1
  N=$2

  if [ -z "$in"  ] || [ ! -f "$in" ] ; then
    error "Invalid input file: Syntax is $0 <input_file> [<percentage of lines (Default: 10%)>]"
  else
    [ -z "$N" -o "$N" -lt 0 -o "$N" -gt 100 ] && N=10

    while read -r line ; do
      [ $((RANDOM % 100)) -le $N ] && echo "$line"
    done < "$in"
  fi
}

# Perform a faster, recursive and case-ignoring 'grep' search on a GIT repo.
gg() {
  pattern=$1
  path="."
  if [ $# -gt 1 ] ; then
    shift
    path="$*"
  fi
  git grep -iI "$pattern" "$path" | sed -e 's#^\([^:]*\):\(.*\)$#\1 -> \2#g' | grep -iI "$pattern" --color
}

# mkdir -p + cd to newly created directory, in one go
mcd() {
  [ ! -z $1 ] && mkdir -p $1 && cd $1
}

# Typical shortcuts
! is.mac && alias ls='ls --color'
alias grep='grep --color'

# Fantastic when you are leaving the company and want to get all your job in one go
alias git.pull_all='for dir in $(find . -type d -maxdepth 1) ; do (cd $dir && is.repo && git pull) ; done || true'
alias git.clean_all='for dir in $(find . -type d -maxdepth 1) ; do (cd $dir && is.repo && git clean -dfx) ; done || true'
alias git.leaving_today='git.clean_all && git.pull_all && tar -cjvf /tmp/leaving_new_york_never_easy.bz2 . && mv /tmp/leaving_new_york_never_easy.bz2 . && printf "\n\nDone\nCopy \"leaving_new_york_never_easy.bz2\" somewhere and RUN. FAST\n\n"'

# so sweet
alias cd..='cd ..'

# Get you external IP fast
alias ip.mine='dig +short myip.opendns.com @resolver1.opendns.com'

# Get the owner of each branch, last commit and branch name
alias git.owners='is.repo && for branch in `git branch -r | grep -v HEAD`;do echo -e `git show --format="%an ---> %ai %ar" $branch | head -n 1` \\t$branch; done | sort -r'

# converters for files
alias sys.iso_to_utf='iconv --from-code=iso-8859-1 --to-code=utf-8'
alias sys.utf_to_iso='iconv --to-code=iso-8859-1 --from-code=utf-8'

# with X only, paste output of command into clipboard: echo 'AAA' | ccp
if is.mac ; then alias ccp='pbcopy' ; else alias ccp='xclip -selection clipboard' ; fi

# Copy current path to clipboard - needs 'ccp'
alias ccpath='pwd | ccp'

# OSX override of AWK, if installed
is.mac && [ ! -z "$(which gawk)" ] && alias awk='gawk'

# Pushes production, develop, and all tags in one go
alias super.push='git push origin prod  && git push --tags && git push origin develop'

# Starts/stops a local Datascience notebook:  https://github.com/jupyter/docker-stacks/tree/master/datascience-notebook
alias spawn.ds-notebook='_spawn jupyter/datascience-notebook  -v "$(pwd):/home/jovyan/work" -p 8888:8888'
alias despawn.ds-notebook='_despawn jupyter/datascience-notebook'

# Starts/stops a Jupyter notebook being run
alias spawn.notebook='_spawn jupyter/all-spark-notebook  -v "$(pwd):/home/jovyan/work" -p 8888:8888'
alias despawn.notebook='_despawn jupyter/all-spark-notebook'

# Starts/stops a local redis instance
alias spawn.redis='_spawn redis -p 6379:6379'
alias despawn.redis='_despawn redis'

# Starts/stops a memcached instance
alias spawn.memcached='_spawn memcached -p 11211:11211'
alias despawn.memcached='_despawn memcached'

# VIM aliases, for great justice
alias bim="echo 'LOL eres un mamón, es ''vi'' o ''vim'', no va con B... te lo paso por esta' && read && vim $*"
alias vin="echo 'VIN?? 'Vin' qué, Diesel??? Madre mía, que paciencia...' && read && vim $*"

# Random 32-char string
alias rand.str="cat /dev/urandom | base64 | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1"

# Automagically autocomplete repo names and 'cd' into them. Needs a proper base repo dir. Depends on bash_completion.
alias repo='_repo'

# Activate an existing Python 2/3 virtualenv in current directory
alias activate='_activate'
alias activate36='_activate36'
alias activate37='_activate37'

# Install and activate a Python 2/3 Virtualenv in current location
alias virtualenver='_virtualenver'
alias virtualenver36='_virtualenver36'
alias virtualenver37='_virtualenver37'

# Some bash-debugging help
debug.on() {
  export PS4='+(${BASH_SOURCE}:${LINENO}): ${FUNCNAME[0]:+${FUNCNAME[0]}(): }'
}

# Turn off SUPER VERBOSE bash-debugging help
alias debug.off='unset PS4'

# Run locally installed npm binaries
alias npm-exec='PATH=$(npm bin):$PATH'

# Sudo edit /etc/hosts
alias sys.hosts='sudo vim /etc/hosts'

# Restart Emulation Station
alias recalbox.es.restart="curl 'http://recalbox.local/post?action=reboot-es' -H 'Origin: http://recalbox.local' -H 'Accept-Encoding: gzip, deflate' -H 'Accept-Language: en-US,en;q=0.9,es;q=0.8' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.103 Safari/537.36' -H 'Content-Type: application/json' -H 'Accept: */*' -H 'Referer: http://recalbox.local/help' -H 'Connection: keep-alive' -H 'DNT: 1' --data-binary '{}' --compressed"

# Start/ Stop  Forti Vpn
alias vpn.activate="sudo /Users/juanito/Stuff/bgdts/fortivpn-mac/routes.sh add vpn"
alias vpn.deactivate="sudo /Users/juanito/Stuff/bgdts/fortivpn-mac/routes.sh del vpn"
alias vpn.restart="sudo bash -c '/Users/juanito/Stuff/bgdts/fortivpn-mac/routes.sh del vpn && sudo /Users/juanito/Stuff/bgdts/fortivpn-mac/routes.sh add vpn'"

# chdir to to a temporary location
alias cdtmp='cd "$(mktemp -d)"'

# DO NOT VERSION THESE THANKS
[ -f ~/.bash_private_vars ] && source ~/.bash_private_vars
